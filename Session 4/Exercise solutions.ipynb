{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise 1:***\n",
    "\n",
    "Q1: Can you come up with a neural network for the OR gate?\n",
    "<br/>\n",
    "<img align=\"left\" src=\"images/or.png\" height=\"100\" />\n",
    "<img align=\"left\" src=\"http://hyperphysics.phy-astr.gsu.edu/hbase/Electronic/ietron/or.gif\" width=\"410\" /> \n",
    "<br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/>\n",
    "<br/><br/><br/>\n",
    "\n",
    "Hint:\n",
    "    - Step 1: How many input nodes should we have? Do not forget the bias term.\n",
    "    - Step 2: Sketch the neural network and put the variables with names on it, such as $x_1, x_2, b, w_1, w_2$, etc.\n",
    "    - Step 3: Come up with some values for the weight and bias that will give the correct prediction for one of the points.\n",
    "    - Step 4: Update the weight and bias term, if necessary, to give correct predictions for another point as well as the previous one(s). Repeat for the remaining point(s).\n",
    "<br/>\n",
    "\n",
    "Note: You do not need to find the most optimal weights (and consequently the best decision bounadry line). Any weights that correctly classifies the four points will do!\n",
    "\n",
    "***Solution:***\n",
    "![](https://miro.medium.com/max/893/1*iPkjXwYEV6Cjc92Y5H6m_Q.png)\n",
    "\n",
    "\n",
    "\n",
    "Q2: Can you come up with a neural network for the AND gate?\n",
    "<br/>\n",
    "<img align=\"left\" src=\"images/and.png\" height=\"100\" />\n",
    "<img align=\"left\" src=\"http://hyperphysics.phy-astr.gsu.edu/hbase/Electronic/ietron/and.gif\" width=\"410\" /> \n",
    "<br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/>\n",
    "<br/><br/>\n",
    "\n",
    "***Solution:***\n",
    "![](https://miro.medium.com/max/893/1*KUsrt-80RQMHS8_jGhikyw.png)\n",
    "\n",
    "\n",
    "Q3: Would a similar network work for the XOR gate?\n",
    "<br/>\n",
    "<img align=\"left\" src=\"images/xor.png\" height=\"100\" />\n",
    "<img align=\"left\" src=\"http://hyperphysics.phy-astr.gsu.edu/hbase/Electronic/ietron/xor.gif\" width=\"410\" /> \n",
    "<br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/>\n",
    "\n",
    "***Solution:***\n",
    "***No, since the two classes are not linearly separable.***\n",
    "\n",
    "\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise 2:***\n",
    "Can you now come up with a neural network for the XOR gate?\n",
    "    - Would the number of nodes in the input and output layers change as compared to the OR and AND gates above? \n",
    "    - If you were to come up with a minimal network (with the least number of layers and nodes), what would it be?\n",
    "\n",
    "\n",
    "Hint: XOR is equivalent to (NAND) AND (OR) where NAND is the negative of AND. See the truth tables above to verify it.\n",
    "1. It would be easy to come up with a neural network for the NAND gate (how would you get it from the one for the AND gate?) \n",
    "2. Next, combine the NAND gate with the OR gate using AND gate weights. It would make more sense if you give it a try!\n",
    "\n",
    "***Solution:***\n",
    "![](https://miro.medium.com/max/1278/1*crHb1glbJXd6Qhxf8k-Slw.png)\n",
    "\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise 3:*** \n",
    "In the above exercise, we came up with the weights for the neural network for the OR gate by trial-and-error method. Let us derive the **back propagation equations** so that we can find optimal weights for the network starting with random weights.\n",
    "\n",
    "![](https://miro.medium.com/max/1113/0*wOYoifz24Wz_I152.)\n",
    "\n",
    "The forward propagation equations will be:  \n",
    "$ z_1 = w_1 x_1 + w_2 x_2 + b$  \n",
    "$ a_1 = g(z_1) $  \n",
    "$ y_{pred} = a_1 $  \n",
    "\n",
    "\n",
    "Let the activation function be sigmoid \n",
    "$$ g(z) = \\frac{1}{1+e^{-z}} $$\n",
    "Let the cost function be $$ J = \\frac{1}{2} \\sum_{i=1}^4 (y^{(i)} - y_{pred}^{(i)})^2 $$\n",
    "\n",
    "Derive the Back propagation equations by calculating the gradients (partial derivatives):   \n",
    "\n",
    "$$ w_1 := w_1 - \\alpha \\frac{\\partial J}{\\partial w_1} $$  \n",
    "$$ w_2 := w_2 - \\alpha \\frac{\\partial J}{\\partial w_2} $$  \n",
    "$$ b := b - \\alpha \\frac{\\partial J}{\\partial b} $$  \n",
    "\n",
    "Hint: Use the chain rule for derivatives\n",
    "\n",
    "$$ \\frac{d f(y)}{dx} =  \\frac{d f(y)}{dy} \\frac{d y}{dx}$$\n",
    "\n",
    "***Solution:***\n",
    "\n",
    "Let us first calculate $\\frac{\\partial J}{\\partial w_1}$:\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\frac{\\partial J}{\\partial w_1} &= \\frac{\\partial J}{\\partial y_{pred}} \\frac{\\partial y_{pred}}{\\partial w_1} \\\\\n",
    "&= \\frac{\\partial J}{\\partial y_{pred}} \\frac{\\partial a_1}{\\partial w_1} \\\\\n",
    "&= \\frac{\\partial J}{\\partial y_{pred}} \\frac{\\partial g(z_1)}{\\partial w_1} \\\\ \n",
    "&= \\frac{\\partial J}{\\partial y_{pred}} \\frac{\\partial g(z_1)}{\\partial z_1}\\frac{\\partial z_1}{\\partial w_1} \\\\\n",
    "&= (y - y_{pred}) \\ g'(z_1) \\  x_1 \n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "For the sigmoid activation function $g(z) = \\frac{1}{1+e^{-z}}$, the derivative is $g'(z) = g(z) (1-g(z))$ $\\leftarrow$ Verify the derivation.\n",
    "\n",
    "Since $ a_1 = g(z_1) $, we have\n",
    "\n",
    " $$ \\frac{\\partial J}{\\partial w_1} = (y - y_{pred}) \\ a_1 \\ (1-a_1) \\ x_1 $$   \n",
    " $$ \\frac{\\partial J}{\\partial w_2} = (y - y_{pred}) \\ a_1 \\ (1-a_1) \\ x_2 $$  \n",
    " $$ \\frac{\\partial J}{\\partial b} = (y - y_{pred}) \\ a_1 \\ (1-a_1) $$\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
