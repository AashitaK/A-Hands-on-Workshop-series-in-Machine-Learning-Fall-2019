{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Hands-on Workshop series in Machine Learning\n",
    "### Session 5: Primer on Keras\n",
    "#### Instructor: Aashita Kesarwani\n",
    "\n",
    "Now that we know a bit more about neural nets, we will learn how to implement these new ideas with Keras. We will continue to use the Keras python library with TensorFlow backend. Keras provides a user-friendly interface to use TensorFlow and build the models quickly. Both Keras and TensorFlow are robust and powerful python libraries commonly used for deep learning.\n",
    "\n",
    "There are two ways to build models in Keras, sequential and functional. \n",
    "* The sequential API allows us to create layer-by-layer models with multiple inputs and outputs, but is limited in its flexibility. \n",
    "* The functional API allows us to create models where we can connect any layer to any other layer, rather than only the layers immediately adjacent to it. It is useful for more advanced architectures where sequential API no longer suffices.\n",
    "\n",
    "In this primer we will be focusing on the sequential API for ease and clarity.\n",
    "\n",
    "We will work with [Breast Cancer Wisconsin (Diagnostic) Data Set](https://www.kaggle.com/uciml/breast-cancer-wisconsin-data). Let us first import the data into a pandas dataframe `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0         M        17.99         10.38          122.80     1001.0   \n",
       "1         M        20.57         17.77          132.90     1326.0   \n",
       "2         M        19.69         21.25          130.00     1203.0   \n",
       "3         M        11.42         20.38           77.58      386.1   \n",
       "4         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean           ...             radius_worst  texture_worst  \\\n",
       "0         0.2419           ...                    25.38          17.33   \n",
       "1         0.1812           ...                    24.99          23.41   \n",
       "2         0.2069           ...                    23.57          25.53   \n",
       "3         0.2597           ...                    14.91          26.50   \n",
       "4         0.1809           ...                    22.54          16.67   \n",
       "\n",
       "   perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "0           184.60      2019.0            0.1622             0.6656   \n",
       "1           158.80      1956.0            0.1238             0.1866   \n",
       "2           152.50      1709.0            0.1444             0.4245   \n",
       "3            98.87       567.7            0.2098             0.8663   \n",
       "4           152.20      1575.0            0.1374             0.2050   \n",
       "\n",
       "   concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0           0.7119                0.2654          0.4601   \n",
       "1           0.2416                0.1860          0.2750   \n",
       "2           0.4504                0.2430          0.3613   \n",
       "3           0.6869                0.2575          0.6638   \n",
       "4           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  \n",
       "0                  0.11890  \n",
       "1                  0.08902  \n",
       "2                  0.08758  \n",
       "3                  0.17300  \n",
       "4                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = 'data/'\n",
    "df = pd.read_csv(path + 'breast_cancer_data.csv')\n",
    "df.drop([\"id\",\"Unnamed: 32\"], axis=1, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train a neural network to classify the cancer cells into malignant and benign, given by the column *diagnosis* in the above dataframe. There are 30 features that describe the characteristics of the cell nuclei of breast masses and are useful indicators to predict whether the cancer is malignant ('M') and benign ('B')."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check the number of rows and columns in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 31)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract our input features `X` and the target output `y` from the dataframe `df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\"diagnosis\"], axis=1)\n",
    "y = df[\"diagnosis\"].replace({'B': 0, 'M': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to split the data into training and testing sets. This is for model cross-validation, that is once our network is trained using training data, we want to measure its performance on the unseen validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of reproducibility, we seed first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(10)\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing a simple network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the relevant functions from [Keras](https://keras.io/) that we plan to use in our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras import losses\n",
    "\n",
    "input_dim = X_train.shape[1] # size of input variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build a squential, feedforward multilayer perceptron we need to start by constructing an appropriately formatted neural network. Let us first look at the shapes of the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 30) (143, 30) (426,) (143,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_valid.shape, y_train.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we worked out above, we will take in 30 input variables and output a single variable. In this primer we will work out a simple example with one input layer, one hidden layer, and one output layer. Because we are taking in 30 inputs and deterimining one output, we want our first layer to have dimension 30 and our last to have dimension 1.\n",
    "\n",
    "Let us construct a network with a 30-25-1 architecture, meaning that the input layer have thirty nodes, the hidden layers have 25 nodes, and the output layer has a single node for the binary classification - benign or malignant. \n",
    "\n",
    "<img src=\"images/nn1.svg\" />\n",
    "\n",
    "We begin by creating a Sequential model using [Keras Sequential API](https://keras.io/getting-started/sequential-model-guide/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by creating a Sequential model, then using the [`.add()`](https://keras.io/getting-started/sequential-model-guide/) function to add the desired layers. For this example we want each layer to be dense, so each node in one layer is connected to every node in the next.\n",
    "\n",
    "Some notes:\n",
    "* We add layers to the model via the [`.add()`](https://keras.io/getting-started/sequential-model-guide/) method. \n",
    "* Keras API allows us to define various kinds of layers that are useful for more involved architectures, but for the Multi-layer Perceptrons, in which every node is connected to every other node in the consequents layers, we use [`Dense`](https://keras.io/layers/core/) layers. \n",
    "* The very first layer added to the model needs to be given the input shape (`input_shape`) or input dimension (`input_dim`).\n",
    "* The other two properties we will specify for the Dense layers are\n",
    "    * Number of units: We will use 25 nodes for the hidden layer\n",
    "    * Activation function: We will use sigmoid activation\n",
    "    \n",
    "Let us add the first fully-connected (dense) layer with the sigmoid activation using [`.add()`](https://keras.io/getting-started/sequential-model-guide/) method with [`Dense`](https://keras.io/layers/core/) layer. This is the hidden layer with 25 nodes (or units)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=25, input_dim=input_dim, activation=\"sigmoid\")) # Hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we add the output layer. \n",
    "* No need to specify the input size, Keras will automatically take it to be 25 - same as the output size of the previous layer. \n",
    "* We specify the the number of units for this layer to be 1 - to give use the prediction of whether the tumor is benign or malignant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=1, activation=\"sigmoid\")) # Output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check the structure of the network using the [`.summary()`](https://keras.io/models/about-keras-models/) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 25)                775       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 801\n",
      "Trainable params: 801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to give us the desired structure. Keep in mind that in practice we want to optimize the number of nodes per hidden layer and number of hidden layers, while in this example the layers were chosen for explanatory purposes.\n",
    "\n",
    "### Training and testing the model \n",
    "\n",
    "Now that we have defined our network architecture, we need to compile it first using [`compile`](https://keras.io/models/model/) before running it. There are a few keywords that we need to pass:\n",
    "* `optimizer`: We will use the stochastic gradient descent menthod `SGD` for the optimizing the cost/loss function, that we studied earlier. We will set the learning rate (step size) to be `lr=0.001`. There are also a few variants of this method that we will learn and use in the next session.\n",
    "* `loss`: This is nothing but the cost function. We want to build a model for binary classification and hence will use cross-entropy loss, as covered in the logistic classifier in the last session.\n",
    "* `metrics`: We studied a lot of classification metrics in our last session. Here, we will simply use accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=SGD(lr=0.001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we train the model using 10 rounds (epochs) over the entire training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "426/426 [==============================] - 0s 926us/step - loss: 0.6244 - acc: 0.8991\n",
      "Epoch 2/10\n",
      "426/426 [==============================] - 0s 49us/step - loss: 0.6188 - acc: 0.9085\n",
      "Epoch 3/10\n",
      "426/426 [==============================] - 0s 46us/step - loss: 0.6163 - acc: 0.9085\n",
      "Epoch 4/10\n",
      "426/426 [==============================] - 0s 46us/step - loss: 0.6135 - acc: 0.9061\n",
      "Epoch 5/10\n",
      "426/426 [==============================] - 0s 48us/step - loss: 0.6113 - acc: 0.9038\n",
      "Epoch 6/10\n",
      "426/426 [==============================] - 0s 48us/step - loss: 0.6096 - acc: 0.9085\n",
      "Epoch 7/10\n",
      "426/426 [==============================] - 0s 44us/step - loss: 0.6074 - acc: 0.9061\n",
      "Epoch 8/10\n",
      "426/426 [==============================] - 0s 44us/step - loss: 0.6057 - acc: 0.9061\n",
      "Epoch 9/10\n",
      "426/426 [==============================] - 0s 44us/step - loss: 0.6038 - acc: 0.9108\n",
      "Epoch 10/10\n",
      "426/426 [==============================] - 0s 49us/step - loss: 0.6011 - acc: 0.9155\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, verbose=1); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that for each epoch the accuracy is generally increasing and the loss is generally decreasing. We now want to see how well it works on our validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on testing set...\n",
      "143/143 [==============================] - 0s 578us/step\n",
      "[INFO] loss=0.6041, accuracy: 88.1119%\n"
     ]
    }
   ],
   "source": [
    "# show the accuracy on the testing set\n",
    "print(\"Evaluating on testing set...\")\n",
    "(loss, accuracy) = model.evaluate(X_valid, y_valid, batch_size=5, verbose=1)\n",
    "print(\"[INFO] loss={:.4f}, accuracy: {:.4f}%\".format(loss, accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acknowledgment:\n",
    "* The dataset used in this project is the [Breast Cancer Wisconsin (Diagnostic) Data Set](https://www.kaggle.com/uciml/breast-cancer-wisconsin-data)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
