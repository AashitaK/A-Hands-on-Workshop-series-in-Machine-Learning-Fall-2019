{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Hands-on Workshop series in Machine Learning\n",
    "### Session 3: More on `pandas`: Groupby operations\n",
    "#### Instructor: Aashita Kesarwani\n",
    "\n",
    "Today's session:\n",
    "\n",
    "1. More on `pandas`: Groupby operations (40 min)\n",
    "2. Decision Trees and Random Forest (30 min)\n",
    "3. Predicting election results using [ANES (American National Election Study)](https://electionstudies.org/data-center/) data (50 min)\n",
    "\n",
    "##### Groupby operations\n",
    "In the last session, we learned the basics of data manipulation using `pandas`. Today, we will learn the split-apply-combine operations by grouping rows of a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import the relevant python modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# The following two modules matplotlib and seaborn are for plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns # Comment this if seaborn is not installed\n",
    "%matplotlib inline\n",
    "\n",
    "# The module re is for regular expressions\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the [Titanic dataset from Kaggle](https://www.kaggle.com/c/titanic) stored in the `csv` file as a dataframe using [`read_csv`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/'\n",
    "df = pd.read_csv(path + 'titanic.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `head()` function to peek into the first 5 rows (or any number of rows by using `head(n)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Description for the columns](https://www.kaggle.com/c/titanic/data) is as follows.  \n",
    "\n",
    "|Variable|\tDefinition|\tKey|   \n",
    "|:---  |:--- |:---|\n",
    "|PassengerId| Passenger ID |\n",
    "|Survived| \tSurvival|\t0 = No, 1 = Yes |\n",
    "|Pclass\t|Ticket class|\t1 = 1st, 2 = 2nd, 3 = 3rd|\n",
    "|Sex\t|Sex|\t\n",
    "|Age\t|Age in years\t|\n",
    "|SibSp\t|# of siblings / spouses aboard the Titanic\t|\n",
    "|Parch\t|# of parents / children aboard the Titanic\t|\n",
    "|Ticket\t|Ticket number\t|\n",
    "|Fare\t|Passenger fare\t|\n",
    "|Cabin\t|Cabin number\t|\n",
    "|Embarked\t|Port of Embarkation\t|C = Cherbourg, Q = Queenstown, S = Southampton|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the functions [`isnull()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.isnull.html) and [`sum()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sum.html) on the dataframe to find out the number of missing values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detecting missing values is an important first step in Feature Engineering, that is preparing the features (independent variables) to use for building the machine learning models. The next step is to handle those missing values. \n",
    "\n",
    "1. If you consider filling the missing values, what are the possible options? \n",
    "2. Can you make use of other values in that column to fill the missing values? \n",
    "3. Can you make use of other values in that row as well as values in that column to fill the missing values?\n",
    "\n",
    "As we saw earlier, the column *Age* has a lot of missing values. Those missing values can be filled with the median (or mean) age of all passengers.\n",
    "\n",
    "* Can you think of other options to fill the missing age values for the passengers? \n",
    "* Does the title of the passengers' provide useful information about their age? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the exercise session in the last session, we created a new column *Title* that is derived from the column *Name* using regular expressions. Below is the compact repetition of the code to do the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Title'] = df['Name'].apply(lambda name: re.findall(\"\\w+[.]\", name)[0])\n",
    "\n",
    "df.Title.replace({'Ms.': 'Miss.', 'Mlle.': 'Miss.', 'Dr.': 'Rare', 'Mme.': 'Mrs.', \n",
    "                  'Major.': 'Rare', 'Lady.': 'Rare', 'Sir.': 'Rare', 'Col.': 'Rare', \n",
    "                  'Capt.': 'Rare', 'Countess.': 'Rare', 'Jonkheer.': 'Rare', \n",
    "                  'Dona.': 'Rare', 'Don.': 'Rare', 'Rev.': 'Rare'}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us make use of the newly derived *Title* column to fill the age based on the title of the passengers. For this, it would be helpful to group the passengers based on their title to get the median age for each group and then fill the missing age values for passengers with the median age for their title.\n",
    "\n",
    "### 1. [GroupBy object](https://pandas.pydata.org/pandas-docs/version/0.22/groupby.html)\n",
    "\n",
    "We can use [`groupby()`](https://pandas.pydata.org/pandas-docs/version/0.21/generated/pandas.DataFrame.groupby.html) to group the rows of the dataframe based on a column(s), say *Title*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting object is not a dataframe but there are multiple ways to derive a dataframe from the grouped object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the ways to derive a dataframe from a groupby object is by aggregation, that is computing a summary statistic (or statistics) about each group. For example, we can get the median values for the columns in each group of titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Title').median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The median age vary greatly for each group ranging from 3.5 to 48 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Title').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common way to derive a dataframe from a groupby object is by transformation. We create a new column *MedianAge* which consists of the groupwise median age depending on the passengers' title using [`transform()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.transform.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MedianAge'] = df.groupby('Title')['Age'].transform(\"median\")\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we fill in the missing values in the *Age* column using the values in the *MedianAge* column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'] = df['Age'].fillna(df['MedianAge'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop off the *MedianAge* column since we no longer need it and then check for the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('MedianAge', axis=1)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing values in the Age column!\n",
    "\n",
    "In the next section, you will use the `groupby` object and create a new feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Feature engineering on the Titanic dataset to create a new column for group size \n",
    "\n",
    "In this exercise, we are going to create a new column called `GroupSize` to get the size of the group for each passenger. We consider groups to be either family members or those traveling on the same ticket. This feature is derived using three columns *SibSp*, *Parch* and *Ticket*. \n",
    "\n",
    "[Notes](https://www.kaggle.com/c/titanic/data) for the two features *SibSp* and *Parch* are as follows.\n",
    "\n",
    "> SibSp: The dataset defines family relations in this way...  \n",
    "Sibling = brother, sister, stepbrother, stepsister  \n",
    "Spouse = husband, wife (mistresses and fiancÃ©s were ignored)\n",
    "> \n",
    "> Parch: The dataset defines family relations in this way...  \n",
    "Parent = mother, father  \n",
    "Child = daughter, son, stepdaughter, stepson  \n",
    "Some children travelled only with a nanny, therefore parch=0 for them.\n",
    "\n",
    "Create a new column named *Family* by adding the columns *SibSp* and *Parch* and then add 1 to it. Hint: Use `df[\"New_column\"] = df[\"column_1\"] + df[\"column_2\"] + 1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Family'] = df['SibSp'] + df['Parch'] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we check the survival rates with respect to the family size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='Family', y='Survived', data=df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some passengers that appear to be traveling alone by account of their family size were part of a group traveling on the same ticket. To see this, get all the passengers traveling on the ticket \"1601\" (there are 7 of them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['Ticket']=='1601']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can check that there are many tickets shared among passengers that may or may not be family members."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Ticket'].value_counts()[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new column named *TicketCount* that counts the total number of passengers traveling in each passengers' ticket.\n",
    "\n",
    "Hint: \n",
    "- First group passengers based on their tickets using `groupby()` on the *Ticket* column.\n",
    "- For the grouped object, pick any column that has no missing values.\n",
    "- Use `transform()` for this unique identifier column with the function `\"count\"` to create a new column *TicketCount*.\n",
    "\n",
    "For example, we created *MedianAge* using the following code:   \n",
    "```df['MedianAge'] = df.groupby('Title')['Age'].transform(\"median\")```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['TicketCount'] = df.groupby('Ticket')['Name'].transform(\"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us peek into the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the survival rates based on the *TicketCount* using [`sns.barplot()`](https://seaborn.pydata.org/generated/seaborn.barplot.html) (see above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.barplot(x='TicketCount', y='Survived', data=df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does seem that the number of co-travelers have an impact on the survival rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new column named *GroupSize* by picking the maximum value among the columns *Family* and *TicketCount*.   \n",
    "Note: We consider groups to be either family members or those traveling on the same ticket.   \n",
    "Hint: Use built-in [`max()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.max.html) function for pandas on the two relevant columns with the appropriate value for the `axis` parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['GroupSize'] = df[['Family', 'TicketCount']].max(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the survival rates based on the GroupSize using [`sns.barplot()`](https://seaborn.pydata.org/generated/seaborn.barplot.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.barplot(x='GroupSize', y='Survived', data=df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the number of rows where Groupsize is not equal to Family. Similarly, check the number of rows where TicketCount is not equal to Family."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['GroupSize'] != df['Family']].shape[0], df[df['GroupSize'] != df['TicketCount']].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output must be `(97, 191)`. Check your above code, if you get a different output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Merging columns from different datasets (Optional) <a name=\"section7\"></a>:\n",
    "A simple illustration to merge two datasets using [`merge()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'CourseCode': ['PHYS024', 'CSCI35', 'ENGR156'], \n",
    "                   'CourseName': ['Mechanics and Wave Motion', \n",
    "                                  'Computer Science for Insight',\n",
    "                                 'Intro to Comm & Info Theory']})\n",
    "\n",
    "df2 = pd.DataFrame({'Professor': ['Zachary Dodds', 'Vatche Sahakian', \n",
    "                                  'Timothy Tsai', 'Brian Shuve'],\n",
    "                    'CourseCode': ['CSCI35', 'PHYS024',  'ENGR156', 'PHYS024']})\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df2, df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please refer to the documents [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html) and [here](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html) to better grasp how and when to use `merge()` function. \n",
    "\n",
    "#### Merging dataframes from [Instacart Market Basket Analysis](https://www.kaggle.com/c/instacart-market-basket-analysis/data) dataset:\n",
    "We load the four files into separate dataframes:   \n",
    "`aisles.csv`   \n",
    "`departments.csv`  \n",
    "`products.csv`  \n",
    "`order_products__train.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/instacart-market-basket-analysis/'\n",
    "dfa = pd.read_csv(path + 'aisles.csv')\n",
    "dfd = pd.read_csv(path + 'departments.csv')\n",
    "dfp = pd.read_csv(path + 'products.csv')\n",
    "dfo = pd.read_csv(path + 'order_products__train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Familiarize yourself with the dataframes. Hint: Use [`head()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.head.html).  \n",
    "Note: You might want to add the code cells. This can be done in two ways:\n",
    "1. Using `Insert` tab in the top bar of the notebook and then `Insert Cell Above` or `Insert Cell Below`.\n",
    "2. Using the keyboard shortcuts: \n",
    "    1. First press `Esc` key to enter the command mode.\n",
    "    2. Add cell above using `A` or below using `B`.\n",
    "    3. Exit by pressing `Enter/Return` key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal: Get a dataframe consisting of the name of the products along with their aisle names and department names for the order with `order_id` equal to 1.**  \n",
    "This dataframe must have ***8 rows and only three columns:\n",
    "```'product_name', 'aisle', 'department'```***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First slice out 8 rows from the order_products dataframe that corresponds with `order_id` equal to 1 and save it in a new dataframe `df`. Hint: Use conditional on indexing as seen above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = dfo[dfo['order_id'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us have a peek into the dataframe `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe `df` has a column named `product_id`. So, we can merge it with the dataframe `dfp` to get `product_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the dataframes `df` and `dfp` using [`merge()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html) and save the result back to `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.merge(dfp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check whether the new columns are added to the dataframe `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have new columns `aisle_id` and `department_id`. Let us first merge `dfa` with this dataframe to get the column `aisle`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.merge(dfa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check our dataframe `df` again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it should have the column `aisle`. Let us now merge `dfd` with this dataframe to get the column `department`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.merge(dfd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check our dataframe `df` again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we only select 3 columns: `'product_name', 'aisle', 'department'`. Hint: Use indexing with the list of columns as seen above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[['product_name', 'aisle', 'department']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check the dataframe `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us also check the shape of the dataframe `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should be `(8, 3)`. Please check your code above if you get something else."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acknowledgment:\n",
    "* [Titanic dataset from Kaggle](https://www.kaggle.com/c/titanic) dataset openly available in Kaggle is used in the exercises.\n",
    "* [Instacart Market Basket Analysis](https://www.kaggle.com/c/instacart-market-basket-analysis/data) dataset openly available in Kaggle is used in the exercises.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
