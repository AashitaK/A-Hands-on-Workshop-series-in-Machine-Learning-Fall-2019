{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Hands-on Workshop series in Machine Learning\n",
    "### Session 1: Data Manipulation using `pandas`\n",
    "\n",
    "### Meet the Instructor:\n",
    "Aashita Kesarwani  \n",
    "Current job: Scientific Computing Specialist at Harvey Mudd College  \n",
    "Background:  \n",
    "- PhD in Mathematics from Tulane University (Number Theory)\n",
    "- Undergraduate from IIT (Indian Institute of Technology) in Applied Mathematics   \n",
    "\n",
    "Other roles: \n",
    "- Visiting AI Researcher at [deepkapha.ai](https://www.linkedin.com/company/digitalis-kapha-b-v-/)\n",
    "- [Open source contributor](https://pypi.org/user/Aashita/)\n",
    "\n",
    "### Meet the Teaching Assistants: \n",
    "Daniel Ashcroft\n",
    "- Senior Computer Science Major\n",
    "- Interested in artificial intelligence, machine learning, and game design\n",
    "\n",
    "Victoria Lloyd\n",
    "- Sophomore Physics Major\n",
    "- Interested in theoretical and computational physics and the ethics/applications of emerging technologies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What is machine learning?\n",
    "- Learning from data without explicit programming.\n",
    "\n",
    "##### How to approach a problem? \n",
    "- Data exploration and feature engineering \n",
    "- Model building, tuning and testing \n",
    "    \n",
    "#### Topics to be covered today (Data manipulation using `pandas`)\n",
    "- A brief overview of Jupyter Notebook\n",
    "- Pandas dataframes as the data structure for datasets\n",
    "- Converting csv files to dataframes \n",
    "- Slicing dataframes using conditionals as well as iloc and loc methods.\n",
    "- Statistical summary and exploration of dataframes\n",
    "- Detecting and filling missing values in the dataframes \n",
    "- Regular expressions for data extraction\n",
    "- Feature engineering such as creating new features \n",
    "- Basic plots\n",
    "- Basic operations such as dropping rows/columns, replacing values of a column using a dictionary, etc.\n",
    "- Encoding categorical variables\n",
    "- Correlation between features \n",
    "\n",
    "##### Structure of the session:\n",
    "\n",
    "The notebook is divided into the following sections:\n",
    "0. Preliminaries\n",
    "1. Slicing rows and columns from the dataframe\n",
    "2. Exploring the dataset (45 min exercise session)\n",
    "3. Feature Engineering: Creating a new column for the titles of the passengers (30 min exercise session)\n",
    "4. Encoding categorical variables\n",
    "5. Correlation between variables \n",
    "\n",
    "You will follow along with me in some of the sessions and the rest are the exercises that you will work on in groups.\n",
    "\n",
    "##### Note:\n",
    "* Please raise your hand if you have any questions, or need any help anytime during the workshop.\n",
    "* Solutions for all the exercises (including the ones in the follow-along section) will be provided at the end. There will also be a link for the lecture capture.\n",
    "* Please leave us your feedback (form will soon be emailed to you if have signed-up) and it will be gladly taken into account for the next sessions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Preliminaries\n",
    "#### An overview of ***Jupyter Notebook***.\n",
    "Jupyter Notebook is the de facto standard in Data Science inspired by the concept of [literate programming](https://www-cs-faculty.stanford.edu/~knuth/lp.html) introduced by [Donald Knuth](https://amturing.acm.org/award_winners/knuth_1013846.cfm). \n",
    "\n",
    "It is composed of blocks that are called cells.\n",
    "\n",
    "There are two types of cells:\n",
    "* Code cells\n",
    "* Markdown cells (for text such as this cell itself)\n",
    "\n",
    "You can run the code within the cells (No need to use command line) by first selecting the cell and then using `Shift` + `Enter`. Another option is to use the `Run` button at the header at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 2\n",
    "b = 3\n",
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key shortcuts using command mode\n",
    "Press `Esc` to activate the command mode:\n",
    "Shortcuts:\n",
    "* A: Insert cell above\n",
    "* B: Insert cell below\n",
    "* C: Copy \n",
    "* V: Paste \n",
    "* X: Cut \n",
    "* DD: Delete \n",
    "* M: Convert a cell to Markdown cell\n",
    "* Shift: Let's you select multiple cells at once that you can copy/cut/delete.\n",
    "\n",
    "To exit the command mode, simply press `Enter`. You need to first exit the command mode to run/edit the cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python refresher:\n",
    "\n",
    "Q: What are the main data structures in Python?\n",
    "\n",
    "- Strings   \n",
    "Syntax: `A = \"Aashita Kesarwani\"`\n",
    "\n",
    "\n",
    "- Lists   \n",
    "Syntax: `B = [2, 6, 5, 3]`\n",
    "\n",
    "\n",
    "- Dictionaries (key-value pairs)   \n",
    "Syntax: `C = {\"First name\": \"Aashita\", \"Last name\": \"Kesarwani\"}`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = \"Aashita Kesarwani\"\n",
    "B = [2, 6, 5, 3]\n",
    "C = {\"First name\": \"Aashita\", \"Last name\": \"Kesarwani\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: What is slicing in Python?  \n",
    "A: To extract a single(or multiple) character(s) from a string or list.\n",
    "\n",
    "\n",
    "What would `B[1]` in the list `B = [2, 6, 5, 3]` give?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do I get the letter `h` from the string `A = \"Aashita Kesarwani\"`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do I get my entire first name *Aashita* from the string A = \"Aashita Kesarwani\"? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: Can we use Python lists for matrices (or 2-d arrays)?  \n",
    "A: `Mat = [[1, 3], [2, 4]]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mat = [[1, 3], [2, 4]]\n",
    "Mat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mat[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Q: What are the `numpy` arrays? Why do we need them?***\n",
    "\n",
    "`numpy` is one of the commonly used python modules/packages, which stands for numerical python. Numpy arrays are multidimensional arrays that are optimized for computing, especially for operations such as matrix multiplication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to use a python module, we first need to import it. Let us import all the relevant python modules that we are going to use today. Each of them will be introduced later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# The following two modules matplotlib and seaborn are for plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns # Comment this if seaborn is not installed\n",
    "%matplotlib inline\n",
    "\n",
    "# The module re is for regular expressions\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we are giving an alias to the modules we imported: `import numpy as np`. When we use the built-in functions in a module, we need to use the module name, so it is good to have shorter names for them. For example, we will create a `numpy` array using `np.array()` instead of `numpy.array()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.array([1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: What is vectorization?\n",
    "\n",
    "Applying an operation to the entire array at once instead of individual elements, thus eliminating `for` loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Q: What are the `pandas` dataframes? Why do we need them? What is the crucial difference between numpy matrices and pandas dataframes?***\n",
    "\n",
    "Pandas: an excellent tool to work with datasets\n",
    "\n",
    "Dataframes: the central data structure of pandas library\n",
    "- Evolved out of tables\n",
    "- Most suitable for data manipulation tasks  \n",
    "\n",
    "Pandas is built on top of numpy. The crucial difference between numpy matrices and pandas dataframes is that the columns in a Dataframe can be of different datatypes such as numerical, categorical, textual, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load the [Titanic dataset from Kaggle](https://www.kaggle.com/c/titanic) stored in the `csv` file as a dataframe using [`read_csv`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'titanic/'\n",
    "df = pd.read_csv(path + 'train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If using Google Colab, the above will give you an error.\n",
    "\n",
    "You will have to first download the `train.csv` file from the [Github repository](https://github.com/AashitaK/A-Hands-on-Workshop-series-in-Machine-Learning/Session-1/titanic/) then manually upload it to Colab using: \n",
    "```python\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "```\n",
    "\n",
    "Then, load the file into pandas dataframe using `read_csv`:\n",
    "```python\n",
    "df = pd.read_csv('train.csv')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it turns out to be rather big dataset to display, we can comment the above cell by adding # in front of df and run it again to get rid of the output.\n",
    "\n",
    "Next, let's check the numbers of rows and columns in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the dataset consists of 891 rows and 12 columns.\n",
    "\n",
    "We use `head()` function to peek into the first 5 rows (or any number of rows by using `head(n)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Titanic dataset](https://www.kaggle.com/c/titanic) that we will explore today is sourced from a [Kaggle](https://www.kaggle.com/) beginner-level competition.  \n",
    "\n",
    "Goal of the competition: To apply the tools of machine learning to predict which passengers survived the Titanic tragedy.\n",
    "\n",
    "[Description for the columns](https://www.kaggle.com/c/titanic/data) is as follows.  \n",
    "\n",
    "|Variable|\tDefinition|\tKey|   \n",
    "|:---  |:--- |:---|\n",
    "|PassengerId| Passenger ID |\n",
    "|Survived| \tSurvival|\t0 = No, 1 = Yes |\n",
    "|Pclass\t|Ticket class|\t1 = 1st, 2 = 2nd, 3 = 3rd|\n",
    "|Sex\t|Sex|\t\n",
    "|Age\t|Age in years\t|\n",
    "|SibSp\t|# of siblings / spouses aboard the Titanic\t|\n",
    "|Parch\t|# of parents / children aboard the Titanic\t|\n",
    "|Ticket\t|Ticket number\t|\n",
    "|Fare\t|Passenger fare\t|\n",
    "|Cabin\t|Cabin number\t|\n",
    "|Embarked\t|Port of Embarkation\t|C = Cherbourg, Q = Queenstown, S = Southampton|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: What are the features? \n",
    "\n",
    "Features are nothing but the variables in our model or the columns in our dataset. For example, `PClass`, `Age`, `Sex`, `Fare`, etc. are features for this particular dataset.\n",
    "\n",
    "The final goal is to design a model to predict whether a passenger survives or not. \n",
    "* Which of the above features seem like important predictors? \n",
    "* How can you analyse the data in view of this objective?\n",
    "    \n",
    "Q: What is feature engineering?\n",
    "* Detecting and handling missing values\n",
    "* Encoding categorial features into numerical values\n",
    "* Creating new features from the existing ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Selecting rows and columns from the dataframe\n",
    "\n",
    "How do we select a column from the dataframe? Say, we want to select the *Name* column from the dataframe. \n",
    "\n",
    "Remember, we used square brackets for indexing lists, strings and numpy arrays in Python, for example `A[0]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Name'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we do not want all the rows in the output, we have used `head()` function at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we select multiple columns? Suppose we want to select the columns *Name, Sex* and *Age* from the dataframe. Hint: Use a list of columns inside the square brackets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also select rows by putting a certain condition on a column. Say, we want only those rows for which the gender is *'female'*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"Sex\"] == \"female\"].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to retrieve only the female passengers traveling in the first class. \n",
    "Hint: Add another conditional `df['Pclass']==1` to the above code using & and make sure to wrap the two conditionals with parenthesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get the number of passengers using the shape method which gives us both the number of columns and the number of rows. Write the code to count the number of female passengers traveling in the first class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The `loc` and `iloc` methods\n",
    "So far, we have seen how to retrieve either some select columns or certain rows based on conditionals. What if we want to slice off a portion of the dataframe with some specific rows and columns? We use `.loc[]` or `.iloc[]` methods for this purpose. \n",
    "* `.iloc[]` method is primarily integer position based and gets rows/columns at particular positions in the index (so it only takes integers). \n",
    "* `loc[]` method is label based and gets rows/columns with particular labels from the index.\n",
    "\n",
    "The `loc[]` method allows us to put conditions on rows and retrieve select columns simultaneously.\n",
    "\n",
    "For example, we want to get the name and the survival information for all the adults above 70 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Age']>70, ['Name', 'Survived']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the code to retrieve the **name, age and survival** information for all the **female passengers traveling in the first class**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `iloc[]` method let us retrieve rows by passing sequence of indexes. For example, we can select the rows numbered 100th to 105th. The indexing works exactly like python lists and numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[100:106]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the code to retrieve every 100th row from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the code to retrieve the last 10 rows from the dataframe using `iloc[]` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions for the exercise session:\n",
    "- There are two exercise sections (section 2 and 3) below and they are alloted 45 min and 30 min respectively.\n",
    "- The exercise involves new concepts not covered in the guided session above. Please feel free to ask questions and take help from the instructor and/or TAs.\n",
    "- The hints are provided for the each of the exercises. The built-in functions to be used for them are provided with a clickable link to the user manual. \n",
    "- The exercise sessions are time-bound and you are encouraged to work in groups to speed things up! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Exploring the dataset (45 min)\n",
    "\n",
    "Use [`describe`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html) function for numerical features (columns) to get a brief overview of the statistics of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same as above for qualitative (non-numerical) features. Hint: Use `include=['O']` parameter in the [`describe`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Use the built-in pandas function to count the number of surviving and non-surviving passengers. Hint: Use [`value_counts()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html) on the column `df['Survived']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a pie chart of the same using `matplotlib`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axis('equal') \n",
    "plt.pie(df['Survived'].value_counts(), labels=('Died', \"Survived\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a bar chart for the survival rate among male and female passengers using `seaborn`. Here is [Seaborn cheatsheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Python_Seaborn_Cheat_Sheet.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = 'Sex', y = 'Survived', data = df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the survival rate among passengers in each ticket class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check the survival rate among both genders within the three ticket classes as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='Pclass', y='Survived', hue='Sex', data=df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above chart, do you think that the gender affect the chance of survival for all the three ticket classes equally? Or does it seem like gender's effect is more pronounced for a certain ticket class passengers than others? We plot the  point estimates and confidence intervals for each sub-category to see it more clearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pointplot(x='Sex', y='Survived', hue='Pclass', data=df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the steeper slope for the second class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that gender and ticket class put together give more information about the survival chance than both of them separately. Please feel free to later explore other variables and combination of variables in depth in your own time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many children were on board? Hint: Use indexing on rows using conditional on the *Age* column and then the [`shape`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.shape.html) method to count the rows as seen above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many of the children on board survived? Hint: Add another conditional for the *Survived* column to the above code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the functions [`isnull()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.isnull.html) and [`sum()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sum.html) on the dataframe to find out the number of missing values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detecting missing values is an important first step in Feature Engineering, that is preparing the features (independent variables) to use for building the machine learning models. The next step is to handle those missing values. Depending on the data, sometimes it is a good idea to drop the rows or columns that have some or a lot of missing values, but that also means discarding relevant information. Another way to handle missing values is to fill them with something appropriate. \n",
    "\n",
    "1. Discuss the pros and cons of dropping the rows and/or columns with missing values in general. Should you drop none, all or some of the columns for this particular dataset in view of building the predictive model? Same question for dropping the rows with missing values.\n",
    "3. If you consider filling the missing values, what are the possible options? Can you make use of other values in that column to fill the missing values? Can you make use of other values in that row as well as values in that column to fill the missing values \n",
    "4. Can the title in the name column be used for guessing a passengers' age based on the age values of other passengers with the same title?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the most common port of embarkment? Hint: Check the frequency (counts) of each value in the Embarked column using the built-in function [`value_counts()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html) as seen above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw above, there are missing values in the column for *Embarked*. Fill them with the most commonly occuring value. Hint: Use [`fillna()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check whether the missing values for the *Embarked* column is indeed filled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If not, there are two options to fix this. One is to set `inplace` parameter in the `fillna()` function as `True` and another is to use assignment operator `=` as in `df = df.function()`. \n",
    "\n",
    "***Question***: Why is the `inplace` keyword False by default? This is true not just for `fillna()` but for most built-in functions in pandas. \n",
    "\n",
    "Answer: To facilitate method chaining or piping i.e. invoking multiple operations one after the other. For example, `df.isnull().sum()` used above. Chaining is more commonly used in pandas as compared to another programming style i.e. using nested function calls. Please read more [here](https://towardsdatascience.com/the-unreasonable-effectiveness-of-method-chaining-in-pandas-15c2109e3c69), if interested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should remove the *Cabin* column from the DataFrame -- too many values are missing. Hint: Use [`drop()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html) with appropriate value for the `axis` keyword. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check whether the column is indeed dropped. If not, modify the code above accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the age of the oldest person on board? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all the passenger information for the oldest person on board. Hint: Use [`loc[]`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.loc.html) method with [`idxmax()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.idxmax.html) for the Age column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Feature Engineering: Creating a new column for the titles of the passengers (30 min)\n",
    "\n",
    "The real-world datasets many-a-times contain useful information in the textual format. Text mining is an important area of data science and one of the most powerful tool is [regular expressions](https://www.gnu.org/software/sed/manual/html_node/Regular-Expressions.html) that are not specific to python, but have much wider applications.\n",
    "\n",
    "In this section, you are going to create a new feature for the titles of the passengers derived from their names using regular expressions. For that, let us first take a look at the passengers' names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:20, 'Name'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice one of the identifying characteristics of the titles above are that they end with a period. Regular expressions are very useful in the process of such data extraction and we will use them using the python module `re` to extract the titles from the *Name* column. We will first use regular expressions characters to construct a pattern and then use built-in function `findall` for pattern matching.\n",
    "\n",
    "Some useful regular expression characters:\n",
    "- `\\w`: pattern must contain a word character, such as letters.\n",
    "- `[ ]`: pattern must contain one of the characters inside the square brackets. If there is only one character inside the square brackets, for example `[.]`, then the pattern must contain it.\n",
    "\n",
    "Let's try this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(\"\\w\\w[.]\", 'Braund, Mr. Owen Harris')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It worked! It returned a list instead of the string, so we use indexing to get the first element of the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(\"\\w\\w[.]\", 'Braund, Mr. Owen Harris')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try it on another name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(\"\\w\\w[.]\", 'Heikkinen, Miss. Laina')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we want a pattern that automatically detects the length of the title and returns the entire title.\n",
    "\n",
    "For regular expressions, \\+ is added to a character/pattern to denote it is present one or more times. For example, `\\w+` is used to denote one or more word characters. Fill in the regular expression in the below cell that will detect a period preceeded by one or more word characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should be `'Miss.'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary: For pattern matching the titles using regular expressions:\n",
    "- First we make sure it contains a period by using `[.]`. \n",
    "- Secondly, the period must be preceeded by word characters (one or more), so we use `\\w+[.]`.\n",
    "\n",
    "Write a function `get_title` that takes a name, extracts the title from it and returns the title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the function is working properly by running the following two cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_title('Futrelle, Mrs. Jacques Heath (Lily May Peel)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should be `'Mrs.'`. Note: Make sure that the funtion returns a string and not a list. Please modify the above function accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_title('Simonius-Blumer, Col. Oberst Alfons')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should be `'Col.'`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new column named Title and extract titles from the Name column using the above function `get_title`. Hint: Use built-in [`map()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.map.html) function. The syntax is `df['New_column'] = df['Relevant_column'].map(function_name)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us peek into the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all the unique values for the titles along with their frequency. Hint: Use an inbuilt pandas function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to replace the various spellings of the same title to a single one. Hint: Use the below dictionary with the [`replace`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.replace.html) function\n",
    "\n",
    "`title_dictionary = {'Ms.': 'Miss.', 'Mlle.': 'Miss.', \n",
    "              'Dr.': 'Rare', 'Mme.': 'Mrs.', \n",
    "              'Major.': 'Rare', 'Lady.': 'Rare', \n",
    "              'Sir.': 'Rare', 'Col.': 'Rare', \n",
    "              'Capt.': 'Rare', 'Countess.': 'Rare', \n",
    "              'Jonkheer.': 'Rare', 'Dona.': 'Rare', \n",
    "              'Don.': 'Rare', 'Rev.': 'Rare'}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all the unique values for the titles along with their frequency to check that the titles are replaced properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the median age of passengers? Hint: Use the inbuilt function [`median`](http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.median.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the median age of passengers with the title 'Miss.'? Hint: Use [`loc[]`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.loc.html) method for slicing off the select rows and the *Age* column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the median age of passengers with the title 'Mrs.'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there a noticeble difference in the median ages for the passengers with the above two titles? Should we take titles into account while filling the missing values for the *Age* column? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the end of the exercise session and the following code is part of the guided session. If you finished this and the above section earlier than the alloted time, then it is time to explore the dataset more on your own by first framing some questions and then using google to find the useful pandas built-in functions. Please feel free to ask for help, if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Encoding categorical variables\n",
    "\n",
    "Let us check the datatype of each column. Hint: Use [`dtypes`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dtypes.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning, our models usually take numbers as inputs rather than strings. We have to convert categorical data into a form the model can recognize.\n",
    "\n",
    "We convert the gender values to numerical values 0 and 1 using [`replace`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.replace.html) with a suitable dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace({'male': 0, 'female': 1})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can go wrong with randomly assigning numbers to categories?\n",
    "\n",
    "There are two kinds of categorical variables based on whether the categories possess an inherent order or not:\n",
    "* Ordinal categorical variables\n",
    "* Inordinal categorical variables\n",
    "\n",
    "For example, passengers' ticket class `Pclass` takes the values 1, 2, and 3. These three categories have an inherent order and hence it is an ordinal categorical variable. On the other hand, gender takes two values - male and female, which have no intrinsic ordering and hence it is an inordinal categorical variable.\n",
    "\n",
    "Doe it mean that we can simply treat the ordinal variables such as `Pclass` as another numerical variable? Can you think of any problem this may cause in our model?\n",
    "\n",
    "Other than a natural order, number also possess certain other properties. For example, the difference between the numbers 1 and 2 is the same as the difference between the numbers 2 and 3. \n",
    "$$ 2-1 == 3-2$$\n",
    "\n",
    "Can we make the same claim for the categories labeled $1, 2,$ and $3$ in our ordinal variables `Pclass`?\n",
    "\n",
    "So, converting categories to numbers means adding untrue assumptions that may or may not adversely affect our model. \n",
    "\n",
    "To address this, the commonly used method is one-hot encoding. In this method, we build a one-hot encoded vector with dimension equal to the number of classes in the categories. This vector consists of all 0's except for a 1 corresponding to the class of the instance. For example, the *Embarked* column will have one-hot encoded vectors of [1,0,0], [0,1,0] and [0,0,1] representing each of the three possible ports. This means that we will have three columns for the *Embarked* columns - one for each port and the values for these columns would simply be 1 or 0.\n",
    "\n",
    "One-hot encoding is accomplished in pandas using [`get_dummies`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html) as given below. It simply creates a column for each class of a categorical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(df['Embarked']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want the column names to be `'Port_C', 'Port_Q', 'Port_S'`. Make use of the [`prefix` ](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html) keyword in `get_dummies` to alter the column names and save the one-hot encoded vectors to a new dataframe named `port_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "port_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concat the two dataframes `df` and `port_df` using [`concat`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html) and save the resulting dataframe in `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- One of the columns in the one-hot encoding obtained in the above manner is always redundant. In case of features with just two classes such as gender in our dataset, one-hot encoding is not truly useful. One of its column is same as what we obtained by simply replacing classes with 0 and 1 and the other is redundant.  \n",
    "- The main disadvantage of using one-hot encoding is the increase in the number of features that can negatively affect our model which we will discuss in the later sessions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Correlation between variables \n",
    "\n",
    "What are the possible ways to understand the correlation of features with survival? \n",
    "\n",
    "Pearson correlation coefficients measures the linear correlation between the variables.\n",
    "\n",
    "$$\\rho_{X,Y} = \\frac{cov(X, Y)}{\\sigma_X, \\sigma_Y}$$\n",
    "where \n",
    "- $cov(X, Y)$ is the covariance.    \n",
    "- $\\sigma_X, \\sigma_Y$ are standard deviations of $X$ and $Y$ respectively.\n",
    "\n",
    "The correlation between two variables ranges from -1 to 1. The closer in absolute value a correlation is to 1, the more dependent two features are each other.\n",
    "\n",
    "We can get the correlation matrix for the variables (columns) in the dataset using the built-in function `corr()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* From the above matrix, note which feature has the highest correlation with the survival. \n",
    "* Do features have high correlation among themselves? \n",
    "* Note that this matrix has excluded some categorical variables like gender, port of embarkment, etc. \n",
    "\n",
    "The correlation matrix can also be visualized using heatmaps as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df.corr();\n",
    "plt.title('Pearson Correlation of Features', y=1.05, size=15)\n",
    "sns.heatmap(correlation_matrix);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acknowledgment:\n",
    "* [Titanic dataset from Kaggle](https://www.kaggle.com/c/titanic) dataset openly available in Kaggle is used in the exercises.\n",
    "\n",
    "\n",
    "In the next session, you will learn two machine learning algorithms and work to build a prediction model on an Election Dataset by [American National Election Studies](https://electionstudies.org/). The feature engineering you learnt today will be integral to prepare the data before applying the machine learning algorithms on it. Please make sure to finish the exercise involving regular expressions. \n",
    "\n",
    "Please make sure to fill the feedback form, it is highly appreciated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
